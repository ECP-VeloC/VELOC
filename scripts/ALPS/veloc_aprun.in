#!/bin/bash

# requires: aprun

launcher="aprun"
prog="veloc_$launcher"

libdir="@X_LIBDIR@"
bindir="@X_BINDIR@"

# Print usage
if [ -z "$1" ]; then
    echo USAGE:
    echo ""
    echo "veloc_$launcher <args ...>"
    echo ""
    exit 0
fi

# if VELOC is disabled, just do a normal run and exit
if [ "$VELOC_ENABLE" == "0" ] ; then
  $launcher "$@"
  exit $?
fi

# turn on verbosity
if [ -n "$VELOC_DEBUG" ]; then
  if [ $VELOC_DEBUG -gt 0 ] ; then
    set -x
  fi
fi

# make a record of start time
timestamp=`date`
echo "$prog: Started: $timestamp"

# TODO: if not in job allocation, bail out

jobid=`$bindir/veloc_env --jobid`

# get the nodeset of this job
if [ -z "$VELOC_NODELIST" ] ; then
  nodelist=`$bindir/veloc_env --nodes`
  if [ $? -eq 0 ] ; then
    VELOC_NODELIST=$nodelist
  fi
fi
if [ -z "$VELOC_NODELIST" ] ; then
  echo "$prog: ERROR: Could not identify nodeset"
  exit 1
fi
export VELOC_NODELIST

# get prefix directory
prefix=`pwd`

## Parse checkjob to get the used and maximum job time and compute the end time
## of the allocation in seconds since the epoch.
#to_seconds () {
#	   h=`echo $1 | cut -d ":" -f 1`
#	   m=`echo $1 | cut -d ":" -f 2`
#	   s=`echo $1 | cut -d ":" -f 3`
#	   echo $((10#$h * 3600 + 10#$m * 60 + 10#$s))
#}
#raw_used_time=`checkjob $PBS_JOBID | grep WallTime: | sed "s/ \+/ /g"| cut -d " " -f 2`
#raw_max_time=`checkjob $PBS_JOBID | grep WallTime: | sed "s/ \+/ /g"| cut -d " " -f 4`
#used_time=`to_seconds $raw_used_time`
#max_time=`to_seconds $raw_max_time`
#current_time=`date +%s`
#export VELOC_END_TIME=$(($current_time + $max_time - $used_time))

# enter the run loop
down_nodes=""
attempts=0
runs=${VELOC_RETRIES:-0}
runs=$(($runs + 1))
runs=${VELOC_RUNS:-$runs}
while [ 1 ] ; do
  # once we mark a node as bad, leave it as bad (even if it comes back healthy)
  # TODO: This hacks around the problem of accidentally deleting a checkpoint set during distribute
  #       when a relaunch lands on previously down nodes, which are healthy again.
  #       A better way would be to remember the last set used, or to provide a utility to run on *all*
  #       nodes to distribute files (also useful for defragging the machine) -- for now this works.
  keep_down=""
  if [ "$down_nodes" != "" ] ; then
    keep_down="--down $down_nodes"
  fi

  # if this is our first run, check that the free space on the drive meets requirement
  # (make sure data from job of previous user was cleaned up ok)
  # otherwise, we'll just check the total capacity
  free_flag=""
  if [ $attempts -eq 0 ] ; then
    free_flag="--free"
  fi

  # are there enough nodes to continue?
  down_nodes=`$bindir/veloc_list_down_nodes $free_flag $keep_down`
  if [ "$down_nodes" != "" ] ; then
    # print the reason for the down nodes, and log them
    $bindir/veloc_list_down_nodes $free_flag $keep_down --reason

    # if this is the first run, we hit down nodes right off the bat, make a record of them
    if [ $attempts -eq 0 ] ; then
      start_secs=`date +%s`
      echo "VELOC: Failed node detected: JOBID=$jobid ATTEMPT=$attempts TIME=$start_secs NNODES=-1 RUNTIME=0 FAILED=$down_nodes"
    fi

    # determine how many nodes are needed:
    #   if VELOC_MIN_NODES is set, use that
    #   otherwise, use value in nodes file if one exists
    #   otherwise, assume we need all nodes in the allocation
    # to start, assume we need all nodes in the allocation
    num_needed=`$bindir/veloc_glob_hosts --count --hosts $VELOC_NODELIST`
    if [ -n "$VELOC_MIN_NODES" ]  ; then
      # if VELOC_MIN_NODES is set, use that
      num_needed=$VELOC_MIN_NODES
    else
      # try to lookup the number of nodes used in the last run
      num_needed_env=`$bindir/veloc_env --prefix $prefix --runnodes`
      if [ $? -eq 0 ] ; then
        if [ $num_needed_env -gt 0 ] ; then
          # if the command worked, and the number is something larger than 0, go with that
          num_needed=$num_needed_env
        fi
      fi
    fi

    # check that we have enough nodes left to run the job after excluding all down nodes
    num_left=`$bindir/veloc_glob_hosts --count --minus $VELOC_NODELIST:$down_nodes`
    if [ $num_left -lt $num_needed ] ; then
      echo "$prog: (Nodes remaining=$num_left) < (Nodes needed=$num_needed), ending run."
      break
    fi
  fi

  # make a record of when each run is started
  attempts=$(($attempts + 1))
  timestamp=`date`
  echo "$prog: RUN $attempts: $timestamp"

  #original srun command to emulate
  #srun $exclude "$@"
  # aprun doesn't appear to have an equivalent to --exclude
  # on cray_xt, batch script doesn't run on the same node as rank 0 (service node)
  upnodes=""
  if [ -n "$down_nodes" ]; then
     upnodes=`$bindir/veloc_glob_hosts --minus $VELOC_NODELIST:$down_nodes`
  else
     upnodes=$VELOC_NODELIST
  fi
  # strip off the brackets around the node names because aprun doesn't like them
  tmpupnodes=${upnodes%]}
  tmpupnodes=${tmpupnodes:1}

  # launch the application
  $launcher -L $tmpupnodes "$@"

  # any retry attempts left?
  if [ $runs -gt -1 ] ; then
    runs=$(($runs - 1))
    if [ $runs -le 0 ] ; then
      echo "$prog: \$VELOC_RUNS exhausted, ending run."
      break
    fi
  fi

#  # is there a halt condition instructing us to stop?
#  $bindir/veloc_retries_halt --dir $prefix;
#  if [ $? == 0 ] ; then
#    echo "$prog: Halt condition detected, ending run."
#    break
#  fi

  # give nodes a chance to clean up
  sleep 60

#  # check for halt condition again after sleep
#  $bindir/veloc_retries_halt --dir $prefix;
#  if [ $? == 0 ] ; then
#    echo "$prog: Halt condition detected, ending run."
#    break
#  fi
done

# make a record of end time
timestamp=`date`
echo "$prog: Ended: $timestamp"
